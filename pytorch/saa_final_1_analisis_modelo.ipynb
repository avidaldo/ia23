{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ej1: Interpretación de un modelo de red neuronal\n",
    "\n",
    "- ¿Qué tipo de aprendizaje estamos utilizando? ¿Qué tipo de problema se busca resolver?\n",
    "- Explica la arquitectura de la red neuronal utilizada y los hiperparámetros utilizados.\n",
    "- Explica el proceso de entrenamiento y evaluación. ¿Está funcionando bien el modelo?\n",
    "- ¿Qué mejoras se podrían proponer para un mejor abordaje del problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 99.59390258789062\n",
      "Epoch [2/7], Loss: 99.44441986083984\n",
      "Epoch [3/7], Loss: 98.86461639404297\n",
      "Epoch [4/7], Loss: 0.21135300397872925\n",
      "Epoch [5/7], Loss: 0.17388787865638733\n",
      "Epoch [6/7], Loss: 0.1732185035943985\n",
      "Epoch [7/7], Loss: 0.17313863337039948\n",
      "Accuracy on the test set: 0.9982971103542713\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "_ = torch.manual_seed(42)\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "\n",
    "X = df.drop('value', axis=1)\n",
    "y = df['value']\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train_np.values)\n",
    "y_train = torch.FloatTensor(y_train_np.values).view(-1, 1)\n",
    "X_test = torch.FloatTensor(X_test_np.values)\n",
    "y_test = torch.FloatTensor(y_test_np.values)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(30, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x    \n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / len(y_test)\n",
    "    print(f'Accuracy on the test set: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56865\n",
      "         1.0       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56865     0]\n",
      " [   97     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avidaldo/miniconda3/envs/env_torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/avidaldo/miniconda3/envs/env_torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/avidaldo/miniconda3/envs/env_torch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "value\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "Dataset original: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "(modificados nombres de últimas dos columnas y fichero)\n",
    "\n",
    "Se trata de un problema de clasificación binaria (aprendizaje supervisado), con la columna \"value\" como variable objetivo con dos posibles clases ya codificadas con los valores \"0\" y \"1\" y otras 30 *features* predictoras.\n",
    "\n",
    "Se utiliza una red neuronal con tres capas densas (*fully connected*): una de entrada con 30 neuronas, una oculta de 128 y una de salidad de una única neurona. La entrada tiene que ser de tamaño 30 correspondientes con cada una de las 30 *features*. La función de activación utilizada es ReLU en las dos primeras capas. Solo es necesario una neurona de salida ya que es un problema de clasificación binaria. La salida es una única neurona activada con una función sigmoide, devolviendo de este modo la probabilidad de que la instancia pertenezca a la clase \"1\".\n",
    "\n",
    "El modelo se entrena durante 7 *epochs* sin *batch normalization* y se evalúa con el conjunto de test. Se observa un salto llamativo en la función de pérdida tras la 3ª *epoch*. La *accuracy* obtenida es del 99,82%, extremadamente alta. Haciendo modificaciones simples en el modelo o simplemente haciendo pruebas con menos epochs, se puede observar que la precisión final se mantiene en esos números. El modelo no parece estar aprendiendo sino que consigue esa precisión desde el principio.\n",
    "\n",
    "Mostrando un *classification report* y/o la matriz de confusión se observa que el modelo no es capaz de detectar ninguna de las instancias de la clase minoritaria. Esto se debe a que las dos clases del dataset no están equilibradas (*imbalanced dataset*), lo que podemos confirmar mostrando la distribución de las clases.\n",
    "\n",
    "Por tanto para abordar correctamente el problema será necesario definir otras métricas de evaluación, como la precisión, el *recall* o el *F1-score*, y utilizar técnicas de balanceo de clases, como *oversampling* o *undersampling*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
