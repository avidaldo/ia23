{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado\n",
    "\n",
    "Tras estudiar las estrategias de tratamiento de valores numéricos no disponibles como se explica en el [notebook de preprocesado del dataset housing](https://github.com/avidaldo/python-libs-ml/blob/master/end2end/e2e04_preprocessing.ipynb) , propón una nueva solución para utilizando la clase [KNNImputer de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "´KNNImputer´ es una clase proporcionada por scikit-learn que se utiliza para imputar valores faltantes en un conjunto de datos utilizando el algoritmo de los k-vecinos más cercanos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolución\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos los datos y creamos un objeto DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "longitude             float64\n",
      "latitude              float64\n",
      "housing_median_age    float64\n",
      "total_rooms           float64\n",
      "total_bedrooms        float64\n",
      "population            float64\n",
      "households            float64\n",
      "median_income         float64\n",
      "median_house_value    float64\n",
      "ocean_proximity        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creamos un objeto DataFrame a partir de un csv\n",
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "# housing es un objeto DataFrame\n",
    "print(type(housing))\n",
    "# housing tiene la estructura\n",
    "print(housing.dtypes)\n",
    "\n",
    "# definimos las columnas interesantes para que sea mas cómodo de visualizar\n",
    "printRows = [\"housing_median_age\", \"median_income\", \"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de conjuntos de entrenamiento\n",
    "\n",
    "- `train_test_split` from `sklearn.model_selection`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de conjuntos de entrenamiento y prueba mediante muestreo estratificado por ingreso medio\n",
    "# Divide el DataFrame housing en conjuntos de entrenamiento y prueba\n",
    "train_set, test_set = train_test_split(\n",
    "    housing,  # DataFrame\n",
    "    test_size=0.2,  # conjunto de prueba será el 20% del tamaño total del conjunto de datos original\n",
    "    stratify=pd.cut(  # realiza un muestreo estratificado basado en los valores\n",
    "        # selecciono los datos de la columna \"median_income\"\n",
    "        housing[\"median_income\"],\n",
    "        # Los datos se agrupan en intervalos definidos por los límites [0.0, 1.5, 3.0, 4.5, 6.0, np.inf]\n",
    "        bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "        # los datos ee etiquetan con valores [1, 2, 3, 4, 5]\n",
    "        labels=[1, 2, 3, 4, 5],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tengo definido dos conjuntos de datos: `train_set` y `test_set`.\n",
    "\n",
    "- Conjunto de entrenamiento (train_set):\n",
    "\n",
    "  - Este conjunto de datos se utiliza para entrenar el modelo de aprendizaje automático.\n",
    "  - Los modelos se ajustan a los datos de entrenamiento para aprender relaciones entre las características (variables independientes) y la variable objetivo (variable dependiente).\n",
    "\n",
    "- Conjunto de prueba (test_set):\n",
    "\n",
    "  - Este conjunto de datos se utiliza para evaluar el rendimiento del modelo entrenado en datos no vistos.\n",
    "  - Después de entrenar el modelo en el conjunto de entrenamiento, se utiliza el conjunto de prueba para estimar cómo se generalizará el modelo a nuevos datos.\n",
    "  - Esto es importante para evaluar la capacidad del modelo para hacer predicciones precisas sobre datos que no ha visto durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set type = <class 'pandas.core.frame.DataFrame'>\n",
      "test_set type = <class 'pandas.core.frame.DataFrame'>\n",
      "[conjuntos de datos: train_set]\n",
      "       housing_median_age  median_income  median_house_value\n",
      "7525                37.0         1.7158             94300.0\n",
      "6243                35.0         3.7454            156900.0\n",
      "[conjuntos de datos: test_set]\n",
      "        housing_median_age  median_income  median_house_value\n",
      "15946                52.0         3.8274            252000.0\n",
      "18974                22.0         1.6875             87500.0\n"
     ]
    }
   ],
   "source": [
    "# Definimos las columnas interesantes para que sea más cómodo de visualizar\n",
    "# printRows = [\"housing_median_age\", \"median_income\", \"median_house_value\"]\n",
    "\n",
    "# Seguimos trabajando con objetos DataFrame\n",
    "print(\"train_set type =\", type(train_set))\n",
    "print(\"test_set type =\", type(test_set))\n",
    "\n",
    "# Conjunto de entrenamiento (train_set):\n",
    "print(\"[conjuntos de datos: train_set]\\n\", train_set[printRows].head(2))\n",
    "\n",
    "# Conjunto de prueba (test_set):\n",
    "print(\"[conjuntos de datos: test_set]\\n\", test_set[printRows].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesado de datos:\n",
    "\n",
    "##### Eliminamos de `train_set` la columna que queremos usar como entrada del modelo de entrenamiento\n",
    "\n",
    "- Se elimina la columna `median_house_value` del conjunto de entrenamiento `train_set`\n",
    "- es considerada la variable dependiente o etiqueta en el conjunto de datos\n",
    "- objetivo `pueda ser utilizado como entrada en el entrenamiento del modelo`.\n",
    "- acción :\n",
    "  - usamos DataFrame.drop(\"${columnName}\",axis=${1}) para columnas\n",
    "    - `df.drop(['B', 'C'], axis=1)`\n",
    "  - usamos DataFrame.drop(\"${indexName}\",axis=${0}) para index\n",
    "    - `df.drop([0, 1])`\n",
    "- visualización del DataFrame traspuesto para que sea mas legible\n",
    "  - `DataFrame.head().T`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya no tenemos median_house_value\n",
      "                        7525       6243       17209   19571   3067 \n",
      "longitude             -118.24    -117.98    -119.72 -120.94 -119.25\n",
      "latitude                33.91      34.05      34.43   37.59   35.77\n",
      "housing_median_age       37.0       35.0       33.0    16.0    35.0\n",
      "total_rooms            1607.0     2342.0     1028.0  3964.0  1618.0\n",
      "total_bedrooms          377.0      426.0      377.0   824.0   378.0\n",
      "population             1526.0     2176.0      753.0  2622.0  1449.0\n",
      "households              375.0      416.0      356.0   766.0   398.0\n",
      "median_income          1.7158     3.7454     2.3454  2.3152  1.6786\n",
      "ocean_proximity     <1H OCEAN  <1H OCEAN  <1H OCEAN  INLAND  INLAND\n"
     ]
    }
   ],
   "source": [
    "# Procesado de datos\n",
    "# Guardamos la variable dependiente (etiquetas)\n",
    "housing_labels = train_set[\"median_house_value\"].copy()\n",
    "# Eliminamos la columna de la variable dependiente\n",
    "# Sobrescribimos los datos en `proc_data` Processed data\n",
    "proc_data = train_set.drop(\"median_house_value\", axis=1)\n",
    "print(\"ya no tenemos median_house_value\")\n",
    "# mostramos el código traspuesto para que muestre todas las columnas\n",
    "print(proc_data.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificación de valores no disponibles\n",
      "Vemos cuantos Valores nulos hay por columna\n",
      "Column\t\t (count) null val\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        163\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Identificación de valores no disponibles\")\n",
    "print(\"Vemos cuantos Valores nulos hay por columna\")\n",
    "# Identificación de valores no disponibles\n",
    "# en cada columna suma 1 por cada valor nulo que tenga\n",
    "null_values_per_column = (\n",
    "    # el método isnull() es un alias de isna()\n",
    "    proc_data.isna().sum()\n",
    ")\n",
    "print(\"Column\\t\\t (count) null val\")\n",
    "print(null_values_per_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### identificamos las celdas con valores nulos\n",
    "\n",
    "`null_rows_idx = proc_data.isnull().any(axis=1)`\n",
    "\n",
    "- Este código crea una Serie booleana\n",
    "- indica qué filas del DataFrame proc_data contienen al menos un valor nulo.\n",
    "- Utiliza el método isnull() para identificar los valores nulos en cada celda del DataFrame,\n",
    "- y luego any(axis=1) para verificar si al menos uno de los valores a lo largo del eje de las columnas (eje 1) es nulo en cada fila.\n",
    "- Ouput un Objeto Serie con el Index de la celda y el valor falso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con valores nulos:\n",
      "\n",
      "                        10761     18914      7330       7654       7316   \\\n",
      "longitude             -117.87   -122.22    -118.17    -118.26    -118.19   \n",
      "latitude                33.62     38.15      33.98      33.83      33.98   \n",
      "housing_median_age        8.0       7.0       41.0       24.0       36.0   \n",
      "total_rooms            1266.0    5129.0      756.0     3059.0     4179.0   \n",
      "total_bedrooms            NaN       NaN        NaN        NaN        NaN   \n",
      "population              375.0    2824.0      873.0     2064.0     4582.0   \n",
      "households              183.0     738.0      212.0      629.0     1196.0   \n",
      "median_income           9.802    5.5138     2.7321     3.5518     2.0087   \n",
      "ocean_proximity     <1H OCEAN  NEAR BAY  <1H OCEAN  <1H OCEAN  <1H OCEAN   \n",
      "\n",
      "                        4591    6052        16885      20372     19060  \\\n",
      "longitude             -118.28 -117.76      -122.4    -118.88   -122.41   \n",
      "latitude                34.06   34.04       37.58      34.17     38.16   \n",
      "housing_median_age       42.0    34.0        26.0       15.0      37.0   \n",
      "total_rooms            2472.0  1914.0      3281.0     4260.0    1549.0   \n",
      "total_bedrooms            NaN     NaN         NaN        NaN       NaN   \n",
      "population             3795.0  1564.0      1145.0     1701.0     863.0   \n",
      "households             1179.0   328.0       480.0      669.0     275.0   \n",
      "median_income          1.2254  2.8347       6.358     5.1033    2.7457   \n",
      "ocean_proximity     <1H OCEAN  INLAND  NEAR OCEAN  <1H OCEAN  NEAR BAY   \n",
      "\n",
      "                       18261      15137   3328       9149        14307  \\\n",
      "longitude            -122.08    -116.91 -122.72     -118.5     -117.14   \n",
      "latitude               37.37      32.83   38.88      34.46       32.71   \n",
      "housing_median_age      29.0       16.0    29.0       17.0        52.0   \n",
      "total_rooms           1229.0     5203.0  2781.0    10267.0       500.0   \n",
      "total_bedrooms           NaN        NaN     NaN        NaN         NaN   \n",
      "population             707.0     2515.0   890.0     4956.0       480.0   \n",
      "households             194.0      862.0   310.0     1483.0       108.0   \n",
      "median_income         7.1108      4.105  1.9906     5.5061      1.8696   \n",
      "ocean_proximity     NEAR BAY  <1H OCEAN  INLAND  <1H OCEAN  NEAR OCEAN   \n",
      "\n",
      "                        4046       6835        16757   19559      4767   \n",
      "longitude             -118.49    -118.12     -122.48 -120.98    -118.37  \n",
      "latitude                34.13      34.08        37.7    37.6      34.03  \n",
      "housing_median_age       24.0       35.0        33.0    36.0       37.0  \n",
      "total_rooms            4394.0     2248.0      4492.0  1437.0     1236.0  \n",
      "total_bedrooms            NaN        NaN         NaN     NaN        NaN  \n",
      "population             1443.0     1762.0      3477.0  1073.0      966.0  \n",
      "households              528.0      622.0      1537.0   320.0      292.0  \n",
      "median_income         11.2979        3.0      3.0546  2.1779     3.0694  \n",
      "ocean_proximity     <1H OCEAN  <1H OCEAN  NEAR OCEAN  INLAND  <1H OCEAN  \n"
     ]
    }
   ],
   "source": [
    "# índices de las filas con valores nulos\n",
    "null_rows_idx = proc_data.isnull().any(axis=1)\n",
    "\n",
    "# Imprimir las primeras filas de las filas con valores nulos\n",
    "print(\"Filas con valores nulos:\\n\")\n",
    "print(proc_data.loc[null_rows_idx].head(20).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipo de datos de null_rows_idx:\n",
      "<class 'pandas.core.series.Series'>\n",
      "Tipo de datos de la serie [ bool ]\n",
      "\n",
      "[Index] [Value] de null_rows_idx:\n",
      "7525     False\n",
      "6243     False\n",
      "17209    False\n",
      "19571    False\n",
      "3067     False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el tipo de datos de null_rows_idx\n",
    "print(\"\\nTipo de datos de null_rows_idx:\")\n",
    "print(type(null_rows_idx))\n",
    "print(\"Tipo de datos de la serie [\", null_rows_idx.dtype, \"]\")\n",
    "# Imprimir null_rows_idx para ver sus valores\n",
    "print(\"\\n[Index] [Value] de null_rows_idx:\")\n",
    "print(null_rows_idx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Listwise deletion`\n",
    "\n",
    "- [opción 1] Eliminación de las filas con valores nulos\n",
    "  - 1a. eliminar aquellas instancias incompletas\n",
    "  - 1b. eliminar toda fila que tenga un valor na en cualquier columna\n",
    "- [opción 2] Eliminar la columna entera\n",
    "  - 2a. eliminar la columna por su nombre\n",
    "  - 2b. eliminar todas las las columnas con valores nulos\n",
    "  - 2c. modificar los valores nulos de la columna por el valor de la media aritmética\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, households, median_income, ocean_proximity]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminación de las filas con valores nulos `Listwise deletion'\n",
    "# [opción 1] Eliminación de las filas con valores nulos\n",
    "#        - 1a. eliminar aquellas instancias incompletas,\n",
    "#             aunque es problemático porque estamos eliminando información\n",
    "housing_option1 = proc_data.dropna(subset=[\"total_bedrooms\"])\n",
    "housing_option1.loc[\n",
    "    null_rows_idx\n",
    "].head()  # comprobamos que se han eliminado las filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, households, median_income, ocean_proximity]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#         - 1b. eliminar toda fila que tenga un valor na en cualquier columna\n",
    "# eliminamos las filas con valores nulos\n",
    "housing_option1b = proc_data.dropna(axis=0)\n",
    "housing_option1b.loc[\n",
    "    null_rows_idx\n",
    "].head()  # comprobamos que se han eliminado las filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [opción 2] Eliminar la columna entera\n",
    "#    - 2a. eliminar la columna por su nombre\n",
    "\n",
    "\"\"\"\n",
    "Eliminar la columna entera es una opción si no es una variable importante,\n",
    "pero en este caso parece que sí lo es dado que, \n",
    "aunque esa *feature* no es la que más correlaciona directamente con la variable objetivo,\n",
    "es una de las dos con las que se calcula `bedrooms_ratio`,\n",
    "que sí es la segunda más correlacionada.\n",
    "\"\"\"\n",
    "housing_option2 = proc_data.drop(columns=\"total_bedrooms\")\n",
    "housing_option2.loc[null_rows_idx].head()\n",
    "# Si buscamos nulos ahora en housing_option2, no los encontraremos\n",
    "housing_option2.isnull().any(\n",
    "    axis=None\n",
    ")  # comprobamos que no hay valores nulos en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    - 2b. eliminar todas las las columnas con valores nulos\n",
    "\n",
    "# También podríamos eliminar directamente todas las columnas con nulos:\n",
    "proc_data.dropna(axis=1).isnull().any(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10761    434.0\n",
      "18914    434.0\n",
      "7330     434.0\n",
      "7654     434.0\n",
      "7316     434.0\n",
      "Name: total_bedrooms, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#   - 2c. modificar los valores nulos de la columna por el valor de la media aritmética\n",
    "\n",
    "# Imputación de algún valor (la mediana en este caso)\n",
    "median = proc_data[\"total_bedrooms\"].median()\n",
    "housing_option3 = proc_data[\"total_bedrooms\"].fillna(median)\n",
    "print(housing_option3.loc[null_rows_idx].head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       15931      10253   3007       15124      8769 \n",
      "longitude            -122.41    -117.87 -119.01    -116.88    -118.33\n",
      "latitude               37.73      33.88   35.24      32.86      33.79\n",
      "housing_median_age      42.0       25.0     6.0        9.0       29.0\n",
      "total_rooms           2604.0     1808.0    80.0     3049.0     4389.0\n",
      "total_bedrooms         573.0      440.0    16.0      471.0      873.0\n",
      "population            1703.0     1342.0    66.0     1527.0     2069.0\n",
      "households             507.0      454.0    21.0      515.0      901.0\n",
      "median_income         3.4231      3.025   3.125     5.0733     4.1071\n",
      "ocean_proximity     NEAR BAY  <1H OCEAN  INLAND  <1H OCEAN  <1H OCEAN\n",
      "Número de filas con valores nulos: 169\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "3778     -118.40     34.17                24.0       6347.0           431.0   \n",
      "7654     -118.26     33.83                24.0       3059.0           431.0   \n",
      "6814     -118.07     34.10                32.0       4275.0           431.0   \n",
      "18466    -121.75     37.11                18.0       3167.0           431.0   \n",
      "5665     -118.29     33.73                30.0       3161.0           431.0   \n",
      "\n",
      "       population  households  median_income  \n",
      "3778       2945.0      1492.0         3.3545  \n",
      "7654       2064.0       629.0         3.5518  \n",
      "6814       2812.0      1012.0         3.3512  \n",
      "18466      1414.0       482.0         6.8773  \n",
      "5665       1865.0       771.0         2.7139  \n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "#                     Con  SimpleImputer                        #\n",
    "#################################################################\n",
    "# Creamos una instancia de `SimpleImputer`\n",
    "# indicando que queremos imputar los valores nulos con la mediana,\n",
    "#  luego usamos el método `fit()` para calcular la mediana de cada columna\n",
    "# el método `transform()` para aplicar la imputación a todas las columnas.\n",
    "\n",
    "# Vamos a ver cómo se aplicaría este método a todos los campos numéricos del dataframe\n",
    "# (recordemos que 'ocean_proximity' es categorial -valores de texto-,\n",
    "# y no se puede calcular la mediana de un texto).\n",
    "\n",
    "# También se podría utilizar directamente el método `fit_transform()` de `SimpleImputer`\n",
    "# para calcular el valor a imputar (con `fit()`)\n",
    "# y aplicarla (con `transform()`) en un solo paso.\n",
    "#################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carga el conjunto de datos\n",
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "# Generación de conjuntos de entrenamiento y prueba mediante muestreo estratificado por ingreso medio\n",
    "train_set, test_set = train_test_split(\n",
    "    housing,\n",
    "    test_size=0.2,\n",
    "    stratify=pd.cut(\n",
    "        housing[\"median_income\"],\n",
    "        bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "        labels=[1, 2, 3, 4, 5],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Procesado de datos\n",
    "housing = train_set.drop(\n",
    "    \"median_house_value\", axis=1\n",
    ")  # Eliminamos la columna de la variable dependiente\n",
    "housing_labels = train_set[\n",
    "    \"median_house_value\"\n",
    "].copy()  # Guardamos la variable dependiente (etiquetas)\n",
    "# Mostramos los primeros registros del DataFrame transpuesto\n",
    "print(housing.head().T)\n",
    "\n",
    "# Identificación de valores no disponibles\n",
    "# Índices de las filas con valores nulos\n",
    "null_rows_idx = housing.isnull().any(axis=1)\n",
    "print(\n",
    "    \"Número de filas con valores nulos:\", null_rows_idx.sum()\n",
    ")  # Mostramos el número de filas con valores nulos\n",
    "\n",
    "# Creamos una instancia de `SimpleImputer`\n",
    "# indicando que queremos imputar los valores nulos con la mediana\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Seleccionamos las columnas numéricas\n",
    "housing_num = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculamos la mediana de cada columna numérica\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "# Reemplazamos los valores nulos por la mediana\n",
    "housing_tr = pd.DataFrame(\n",
    "    # trasformamos los datos nulos por los datos de la mediana\n",
    "    imputer.transform(housing_num),\n",
    "    columns=housing_num.columns,\n",
    "    index=housing_num.index,\n",
    ")\n",
    "\n",
    "# Mostramos los primeros registros del DataFrame transformado\n",
    "print(\n",
    "    \"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\"\n",
    ")\n",
    "print(housing_tr.loc[null_rows_idx].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     1240      1714    18714      15125      10982\n",
      "longitude          -120.19   -122.33 -122.42    -116.86    -117.83\n",
      "latitude             38.42      38.0   40.57      32.87      33.75\n",
      "housing_median_age    11.0      35.0    10.0       17.0       22.0\n",
      "total_rooms         1568.0    3779.0  7949.0     5799.0     6433.0\n",
      "total_bedrooms       369.0     711.0  1309.0      921.0     1174.0\n",
      "population            82.0    2493.0  3176.0     2630.0     2703.0\n",
      "households            33.0     679.0  1163.0      843.0     1125.0\n",
      "median_income        3.125    2.9781  4.1099     5.0524     4.9957\n",
      "ocean_proximity     INLAND  NEAR BAY  INLAND  <1H OCEAN  <1H OCEAN\n",
      "Número de filas con valores nulos: 172\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "11512    -118.10     33.74                32.0       2035.0           528.6   \n",
      "20372    -118.88     34.17                15.0       4260.0           717.4   \n",
      "18873    -122.22     38.08                37.0       2811.0           555.2   \n",
      "2351     -119.68     36.79                16.0       1551.0           292.8   \n",
      "6814     -118.07     34.10                32.0       4275.0          1041.4   \n",
      "\n",
      "       population  households  median_income  \n",
      "11512       934.0       512.0         4.2287  \n",
      "20372      1701.0       669.0         5.1033  \n",
      "18873      1574.0       516.0         3.1053  \n",
      "2351       1010.0       292.0         3.5417  \n",
      "6814       2812.0      1012.0         3.3512  \n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "#       con algoritmo **K-Nearest Neighbors (KNN)**             #\n",
    "#################################################################\n",
    "# Existen métodos más avanzados como el uso de **módelos de predicción**\n",
    "# (tratando la columna con valores nulos como la variable objetivo\n",
    "# y el resto de columnas como *features*). Por ejemplo,\n",
    "# podría utilizarse el algoritmo **K-Nearest Neighbors (KNN)**\n",
    "# para predecir los valores nulos de 'total_bedrooms'\n",
    "# basándonos en los registros sí etiquetados.\n",
    "#################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Carga el conjunto de datos\n",
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "# Generación de conjuntos de entrenamiento y prueba mediante muestreo estratificado por ingreso medio\n",
    "train_set, test_set = train_test_split(\n",
    "    housing,\n",
    "    test_size=0.2,\n",
    "    stratify=pd.cut(\n",
    "        housing[\"median_income\"],\n",
    "        bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "        labels=[1, 2, 3, 4, 5],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Procesado de datos\n",
    "housing = train_set.drop(\n",
    "    \"median_house_value\", axis=1\n",
    ")  # Eliminamos la columna de la variable dependiente\n",
    "housing_labels = train_set[\n",
    "    \"median_house_value\"\n",
    "].copy()  # Guardamos la variable dependiente (etiquetas)\n",
    "# Mostramos los primeros registros del DataFrame transpuesto\n",
    "print(housing.head().T)\n",
    "\n",
    "# Identificación de valores no disponibles\n",
    "# Índices de las filas con valores nulos\n",
    "null_rows_idx = housing.isnull().any(axis=1)\n",
    "print(\n",
    "    \"Número de filas con valores nulos:\", null_rows_idx.sum()\n",
    ")  # Mostramos el número de filas con valores nulos\n",
    "\n",
    "# Creamos una instancia de `KNNImputer`\n",
    "# para imputar los valores nulos con la estrategia de vecinos más cercanos\n",
    "imputer = KNNImputer(\n",
    "    n_neighbors=5\n",
    ")  # Como argumento ajustas el número de vecinos según tus necesidades\n",
    "\n",
    "# Seleccionamos las columnas numéricas\n",
    "housing_num = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "# Imputamos los valores nulos utilizando KNN\n",
    "housing_tr = pd.DataFrame(\n",
    "    # primero el fit ajusta los datos\n",
    "    # fit : imputador \"aprende\" de los datos (vecino mas cercanos)\n",
    "    #       y calcula cualquier estadística necesaria\n",
    "    # segundo el transform trasforma los datos nulos\n",
    "    # transform : transforma los datos de entrenamiento nulos en valores\n",
    "    #              teniendo aprendiendo de los vecinos cercanos\n",
    "    imputer.fit_transform(housing_num),\n",
    "    columns=housing_num.columns,\n",
    "    index=housing_num.index,\n",
    ")\n",
    "\n",
    "# Mostramos los primeros registros del DataFrame transformado\n",
    "print(\n",
    "    \"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\"\n",
    ")\n",
    "print(housing_tr.loc[null_rows_idx].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
